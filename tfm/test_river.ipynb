{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3W dataset's General Presentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a general presentation of the 3W dataset, to the best of its authors' knowledge, the first realistic and public dataset with rare undesirable real events in oil wells that can be readily used as a benchmark dataset for development of machine learning techniques related to inherent difficulties of actual data.\n",
    "\n",
    "For more information about the theory behind this dataset, refer to the paper **A Realistic and Public Dataset with Rare Undesirable Real Events in Oil Wells** published in the **Journal of Petroleum Science and Engineering** (link [here](https://doi.org/10.1016/j.petrol.2019.106223))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter Notebook presents the 3W dataset in a general way. For this, some tables, graphs, and statistics are presented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Imports and Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import pickle\n",
    "\n",
    "from river import stream, feature_extraction as fx, compose, stats, preprocessing, tree, metrics, evaluate\n",
    "from river import linear_model, optim, drift, anomaly, utils, ensemble\n",
    "\n",
    "import sklearn.model_selection\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.12.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import river\n",
    "river.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Instances' Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, all 3W dataset's instances are loaded and the first one of each knowledge source (real, simulated and hand-drawn) is partially displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class d3w():\n",
    "    '''\n",
    "    Class for managing Petrobras 3W dataset\n",
    "    '''\n",
    "    def __init__(self, path3w):\n",
    "        self.path3w = path3w\n",
    "        self.df = self.__load_df()\n",
    "        return\n",
    "\n",
    "    def __load_df(self):\n",
    "\n",
    "        d = dict()\n",
    "        d['origin'] = []\n",
    "        d['label'] = []\n",
    "        d['path'] = []\n",
    "        d['nlines'] = []\n",
    "        for i in pathlib.Path(self.path3w).iterdir():\n",
    "            if i.stem.isnumeric():\n",
    "                print(i)\n",
    "                label = int(i.stem)\n",
    "                for fp in i.iterdir():\n",
    "                    # Considers only csv files\n",
    "                    if fp.suffix == \".csv\":\n",
    "\n",
    "                        if (fp.stem.startswith(\"SIMULATED\")):\n",
    "                            d['origin'].append('S')\n",
    "                        elif fp.stem.startswith(\"DRAWN\"):\n",
    "                            d['origin'].append('D')\n",
    "                        else:\n",
    "                            d['origin'].append('R')\n",
    "                        \n",
    "                        d['label'].append(label)\n",
    "                        d['path'].append(fp)\n",
    "                        d['nlines'].append(self.file_len(fp)-1)\n",
    "                        \n",
    "        return pd.DataFrame(d)\n",
    "    \n",
    "    def split(self, real=True, simul=True, drawn=True, test_size=0.2, val_size=0.1, sample_n=None):\n",
    "        \n",
    "        tmp0_df = self.get_df(real, simul, drawn)\n",
    "        \n",
    "        if sample_n is not None:\n",
    "            N = len(tmp0_df.index)\n",
    "            if N > sample_n:\n",
    "                ds_list = []\n",
    "                for i, ni in tmp0_df.groupby('label').count().nlines.items():\n",
    "                    ns = ni*sample_n//N\n",
    "                    ds_list.append(tmp0_df[tmp0_df.label == i].sample(n=ns, random_state=200560))\n",
    "                tmp0_df = pd.concat(ds_list)            \n",
    "        \n",
    "        tmp_df, test_df = sklearn.model_selection.train_test_split(tmp0_df, \n",
    "                                                        test_size=test_size, \n",
    "                                                        random_state=200560, \n",
    "                                                        shuffle=True, \n",
    "                                                        stratify=tmp0_df['label'])\n",
    "        \n",
    "        if val_size == 0:\n",
    "            print('Instances Train: {}  Test: {}'.format(len(tmp_df.index), \n",
    "                                                         len(test_df.index)))\n",
    "            return tmp_df.reset_index(drop=True),\\\n",
    "                   test_df.reset_index(drop=True)\n",
    "        \n",
    "        train_df, val_df = sklearn.model_selection.train_test_split(tmp_df, test_size=val_size, \n",
    "                                                        random_state=200560, \n",
    "                                                        shuffle=True, \n",
    "                                                        stratify=tmp_df['label'])\n",
    "        print('Instances Train: {}  Test: {}  Validation: {}'.format(len(train_df.index), \n",
    "                                                                     len(test_df.index), \n",
    "                                                                     len(val_df.index)))\n",
    "        \n",
    "        return train_df.reset_index(drop=True),\\\n",
    "               test_df.reset_index(drop=True),\\\n",
    "               val_df.reset_index(drop=True)\n",
    "    \n",
    "    def file_len(self, filename):\n",
    "        j = 0\n",
    "        with open(filename) as f:\n",
    "            for i, x in enumerate(f):\n",
    "                if x.strip() == '':\n",
    "                    j += 1\n",
    "        return i + 1 - j\n",
    "    \n",
    "    def get_df(self, real=True, simul=True, drawn=True):\n",
    "        sel = []\n",
    "        if real:\n",
    "            sel.append('R')\n",
    "        if simul:\n",
    "            sel.append('S')\n",
    "        if drawn:\n",
    "            sel.append('D')\n",
    "        if sel:\n",
    "            return self.df[self.df['origin'].isin(sel)].drop(columns=['origin']).reset_index(drop=True)\n",
    "    \n",
    "    @property\n",
    "    def all(self):\n",
    "        return self.df.drop(columns=['origin'])\n",
    "    @property\n",
    "    def real(self):\n",
    "        return self.df[self.df['origin']=='R'].drop(columns=['origin']).reset_index(drop=True)\n",
    "    @property\n",
    "    def simul(self):\n",
    "        return self.df[self.df['origin']=='S'].drop(columns=['origin']).reset_index(drop=True)\n",
    "    @property\n",
    "    def drawn(self):\n",
    "        return self.df[self.df['origin']=='D'].drop(columns=['origin']).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pathlib.Path('dset_river.pkl').exists():\n",
    "  with open('dset_river.pkl', 'rb') as f:\n",
    "    dset = pickle.load(f)\n",
    "else:\n",
    "    dset = d3w('../dataset')\n",
    "    with open('dset_river.pkl', 'wb') as f:\n",
    "      pickle.dump(dset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instances Train: 213  Test: 30  Validation: 54\n"
     ]
    }
   ],
   "source": [
    "flist = ['P-PDG', 'P-TPT', 'T-TPT', 'P-MON-CKP', 'T-JUS-CKP', 'P-JUS-CKGL', 'T-JUS-CKGL', 'QGL']\n",
    "categories=[[0,1,2,3,4,5,6,7,8,101,102,103,104,105,106,107,108]]\n",
    "\n",
    "train_df, test_df, val_df = dset.split(real=True, simul=True, drawn=True, test_size=0.1, val_size=0.2, sample_n=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each instance is stored in a CSV file and loaded into a pandas DataFrame. Each observation is stored in a line in the CSV file and loaded as a line in the pandas DataFrame. The first line of each CSV file contains a header with column identifiers. Each column of CSV files stores the following type of information:\n",
    "\n",
    "* **timestamp**: observations timestamps loaded into pandas DataFrame as its index;\n",
    "* **P-PDG**: pressure variable at the Permanent Downhole Gauge (PDG);\n",
    "* **P-TPT**: pressure variable at the Temperature and Pressure Transducer (TPT);\n",
    "* **T-TPT**: temperature variable at the Temperature and Pressure Transducer (TPT);\n",
    "* **P-MON-CKP**: pressure variable upstream of the production choke (CKP);\n",
    "* **T-JUS-CKP**: temperature variable downstream of the production choke (CKP);\n",
    "* **P-JUS-CKGL**: pressure variable upstream of the gas lift choke (CKGL);\n",
    "* **T-JUS-CKGL**: temperature variable upstream of the gas lift choke (CKGL);\n",
    "* **QGL**: gas lift flow rate;\n",
    "* **class**: observations labels associated with three types of periods (normal, fault transient, and faulty steady state).\n",
    "\n",
    "Other information are also loaded into each pandas Dataframe:\n",
    "\n",
    "* **label**: instance label (event type);\n",
    "* **well**: well name. Hand-drawn and simulated instances have fixed names. Real instances have names masked with incremental id;\n",
    "* **id**: instance identifier. Hand-drawn and simulated instances have incremental id. Each real instance has an id generated from its first timestamp.\n",
    "\n",
    "More information about these variables can be obtained from the following publicly available documents:\n",
    "\n",
    "* ***Option in Portuguese***: R.E.V. Vargas. Base de dados e benchmarks para prognóstico de anomalias em sistemas de elevação de petróleo. Universidade Federal do Espírito Santo. Doctoral thesis. 2019. https://github.com/ricardovvargas/3w_dataset/raw/master/docs/doctoral_thesis_ricardo_vargas.pdf.\n",
    "* ***Option in English***: B.G. Carvalho. Evaluating machine learning techniques for detection of flow instability events in offshore oil wells. Universidade Federal do Espírito Santo. Master's degree dissertation. 2021. https://github.com/ricardovvargas/3w_dataset/raw/master/docs/master_degree_dissertation_bruno_carvalho.pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset.all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomGen():\n",
    "    \n",
    "    def __init__(self, dset, flist, target, scaleb=False, out_time=False, ifileb=False):\n",
    "        self.dset = dset\n",
    "        self.flist = flist\n",
    "        self.target = target\n",
    "        self.scaleb = scaleb\n",
    "        self.out_time = out_time\n",
    "        self.ifileb = ifileb\n",
    "        return\n",
    "    \n",
    "    def iter(self, max_n=None):\n",
    "        n = 0\n",
    "        for ifile, p in enumerate(self.dset['path']):\n",
    "            df = pd.read_csv(p, parse_dates=[\"timestamp\"])\n",
    "\n",
    "            if np.any(df[self.target].isna()):\n",
    "                df[self.target] = df[self.target].fillna(method='ffill')\n",
    "            df[self.target] = df[self.target].astype(int) #.apply(str)\n",
    "\n",
    "            for f in self.flist:\n",
    "                nas = np.sum(df[f].isna())\n",
    "                if nas > 0:\n",
    "                    if nas < len(df.index) * 0.2:\n",
    "                        df[f] = df[f].fillna(method='ffill')\n",
    "                    else:\n",
    "                        df[f] = 0\n",
    "            \n",
    "            if self.scaleb:\n",
    "                np.seterr(divide='ignore', invalid='ignore')\n",
    "                dfd = self.scale(df[self.flist]).to_dict(orient='records')\n",
    "                np.seterr(divide='warn', invalid='warn')\n",
    "            else:\n",
    "                dfd = df[self.flist].to_dict(orient='records')\n",
    "            for i, x in enumerate(dfd):\n",
    "                #assert isinstance(df.iloc[i][self.target], np.int32), 'class not an integer!'\n",
    "                result = []\n",
    "                if self.ifileb:\n",
    "                    result.append(ifile)\n",
    "                if self.out_time:\n",
    "                    result. append(df.iloc[i]['timestamp'])\n",
    "                yield result + [x, df.iloc[i][self.target]]\n",
    "                n += 1\n",
    "                if max_n is not None and n > max_n:\n",
    "                    break\n",
    "            if max_n is not None and n > max_n:\n",
    "                break\n",
    "\n",
    "        return\n",
    "    \n",
    "    def scale(self, df):\n",
    "        scale = StandardScaler()\n",
    "        return pd.DataFrame(scale.fit_transform(df[self.flist]), columns=self.flist, index=df.index)\n",
    "\n",
    "    def plot(self, ifile):\n",
    "        \n",
    "        ds = pd.read_csv(self.dset['path'][ifile], parse_dates=[\"timestamp\"])\n",
    "        fig, axs = plt.subplots(nrows=len(self.flist)+1, figsize=(10, 12), sharex=True)\n",
    "        \n",
    "        fig.suptitle(self.dset['path'][ifile])\n",
    "\n",
    "        for i, vs in enumerate(self.flist):\n",
    "            axs[i].plot(ds.timestamp[::60], ds[vs][::60])\n",
    "            axs[i].set_ylabel(vs)\n",
    "        \n",
    "        id = np.argsort(ds[self.target])\n",
    "        t = [ds.timestamp[i] for i in id][::60]\n",
    "        y = [str(ds[self.target][i]) for i in id][::60]\n",
    "        \n",
    "        axs[i+1].scatter(t, y, marker='.')\n",
    "        \n",
    "        axs[i+1].set_ylabel(self.target)\n",
    "        \n",
    "        axs[i+1].set_xlabel('Date')\n",
    "        \n",
    "        for ax in axs:\n",
    "            ax.grid(visible=True)\n",
    "\n",
    "        plt.show()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2017-02-01 02:02:07 {'P-PDG': 0.0, 'P-TPT': 1.726355710248412, 'T-TPT': 1.6877002420865492, 'P-MON-CKP': 0.16879165859933157, 'T-JUS-CKP': 0.8731632851640091, 'P-JUS-CKGL': -1.7323051228495974, 'T-JUS-CKGL': 0.0, 'QGL': 0.0} 0\n",
      "0 2017-02-01 02:02:08 {'P-PDG': 0.0, 'P-TPT': 1.7211893794340596, 'T-TPT': 1.6877002420865492, 'P-MON-CKP': 0.21591556364734954, 'T-JUS-CKP': 0.8541981839009655, 'P-JUS-CKGL': -1.7313436073904254, 'T-JUS-CKGL': 0.0, 'QGL': 0.0} 0\n",
      "0 2017-02-01 02:02:09 {'P-PDG': 0.0, 'P-TPT': 1.7160230486197072, 'T-TPT': 1.6877002420865492, 'P-MON-CKP': 0.2630394686953675, 'T-JUS-CKP': 0.8352572420026301, 'P-JUS-CKGL': -1.7313436073904254, 'T-JUS-CKGL': 0.0, 'QGL': 0.0} 0\n",
      "0 2017-02-01 02:02:10 {'P-PDG': 0.0, 'P-TPT': 1.7108567178053549, 'T-TPT': 1.6877002420865492, 'P-MON-CKP': 0.3101633737433855, 'T-JUS-CKP': 0.8163163001042605, 'P-JUS-CKGL': -1.7313436073904254, 'T-JUS-CKGL': 0.0, 'QGL': 0.0} 0\n"
     ]
    }
   ],
   "source": [
    "gen = CustomGen(dset.all, flist, 'class', scaleb=True, out_time=True, ifileb=True)\n",
    "n = 0\n",
    "for i, time, x, t in gen.iter():\n",
    "    print(i, time, x, t)\n",
    "    n += 1\n",
    "    if n > 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen.plot(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for t, r in df[flist].iterrows():\n",
    "    print(t, r.to_dict())\n",
    "    i += 1\n",
    "    if i > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "#scaler = preprocessing.RobustScaler()\n",
    "\n",
    "rmean = utils.Rolling(stats.Mean(), window_size=900)\n",
    "rSEM = utils.Rolling(stats.SEM(ddof=1), window_size=900)\n",
    "rMax = stats.RollingMax(window_size=900)\n",
    "rMin = stats.RollingMin(window_size=900)\n",
    "rtree = tree.HoeffdingTreeClassifier()\n",
    "arfc = ensemble.AdaptiveRandomForestClassifier(seed=200560, leaf_prediction=\"nba\", max_depth=4)\n",
    "#loss = optim.losses.MultiClassLoss()\n",
    "loss = optim.losses.CrossEntropy()\n",
    "#rlr = linear_model.LogisticRegression(optimizer=optim.Adam(.01), loss=loss)\n",
    "#metric = metrics.Accuracy()\n",
    "#metric = metrics.BalancedAccuracy()\n",
    "metric = metrics.ClassificationReport()\n",
    "\n",
    "model = compose.TransformerUnion()\n",
    "for f in flist:\n",
    "    model += fx.Agg(on=f, by = None, how=rmean)\n",
    "    model += fx.Agg(on=f, by = None, how=rSEM)\n",
    "    model += fx.Agg(on=f, by = None, how=rMax)\n",
    "    model += fx.Agg(on=f, by = None, how=rMin)\n",
    "#model |= compose.Discard(flist[0])\n",
    "#model |= scaler\n",
    "#model |= arfc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.debug_one(next(gen.iter())[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = CustomGen(train_df, flist, 'class', scaleb=True, out_time=False)\n",
    "evaluate.progressive_val_score(dataset=gen.iter(max_n=None), model=model, metric=metric, delay=1800, print_every=2*3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88799 new file 1\n",
      "115798 new file 2\n",
      "122958 new file 3\n",
      "197357 new file 4\n",
      "226656 new file 5\n",
      "315456 new file 6\n",
      "342455 new file 7\n",
      "360372 new file 8\n",
      "367506 new file 9\n",
      "396805 new file 10\n",
      "403981 new file 11\n",
      "414650 new file 12\n",
      "443949 new file 13\n",
      "470948 new file 14\n",
      "488705 new file 15\n",
      "506683 new file 16\n",
      "517350 new file 17\n",
      "546649 new file 18\n",
      "564294 new file 19\n",
      "582260 new file 20\n",
      "623438 new file 21\n",
      "641313 new file 22\n",
      "648432 new file 23\n",
      "666361 new file 24\n",
      "695660 new file 25\n",
      "713630 new file 26\n",
      "742929 new file 27\n",
      "772228 new file 28\n",
      "799227 new file 29\n",
      "806369 new file 30\n",
      "816893 new file 31\n",
      "823955 new file 32\n",
      "841858 new file 33\n",
      "852396 new file 34\n",
      "881695 new file 35\n",
      "888863 new file 36\n",
      "906579 new file 37\n",
      "924354 new file 38\n",
      "984353 new file 39\n",
      "1041352 new file 40\n",
      "1167615 new file 41\n",
      "1196914 new file 42\n",
      "1204035 new file 43\n",
      "1211169 new file 44\n",
      "1228977 new file 45\n",
      "1255976 new file 46\n",
      "1344776 new file 47\n",
      "1362712 new file 48\n",
      "1392011 new file 49\n",
      "1399179 new file 50\n",
      "1417138 new file 51\n",
      "1446437 new file 52\n",
      "1473436 new file 53\n",
      "1502735 new file 54\n",
      "1509890 new file 55\n",
      "1536889 new file 56\n",
      "1566188 new file 57\n",
      "1584120 new file 58\n",
      "1602013 new file 59\n",
      "1619842 new file 60\n",
      "1649141 new file 61\n",
      "1667037 new file 62\n",
      "1696336 new file 63\n",
      "1714180 new file 64\n",
      "1732072 new file 65\n",
      "1749705 new file 66\n",
      "1776704 new file 67\n",
      "1803703 new file 68\n",
      "1821651 new file 69\n",
      "1839329 new file 70\n",
      "1868628 new file 71\n",
      "1875779 new file 72\n",
      "1879090 new file 73\n",
      "1924689 new file 74\n",
      "1931789 new file 75\n",
      "1938974 new file 76\n",
      "1956932 new file 77\n",
      "1962546 new file 78\n",
      "1967002 new file 79\n",
      "1984897 new file 80\n",
      "1995546 new file 81\n",
      "2022545 new file 82\n",
      "2082544 new file 83\n",
      "2109543 new file 84\n",
      "2136543 new file 85\n",
      "2154406 new file 86\n",
      "2181405 new file 87\n",
      "2199365 new file 88\n",
      "2217057 new file 89\n",
      "2234357 new file 90\n",
      "2244970 new file 91\n",
      "2255753 new file 92\n",
      "2285052 new file 93\n",
      "2359451 new file 94\n",
      "2377400 new file 95\n",
      "2384503 new file 96\n",
      "2730104 new file 97\n",
      "2759403 new file 98\n",
      "2777107 new file 99\n",
      "2804106 new file 100\n",
      "2833405 new file 101\n",
      "2851380 new file 102\n",
      "2887241 new file 103\n",
      "2914240 new file 104\n",
      "2941239 new file 105\n",
      "2959175 new file 106\n",
      "2986174 new file 107\n",
      "3013173 new file 108\n",
      "3031062 new file 109\n",
      "3038238 new file 110\n",
      "3067537 new file 111\n",
      "3094536 new file 112\n",
      "3156535 new file 113\n",
      "3163694 new file 114\n",
      "3225693 new file 115\n",
      "3314492 new file 116\n",
      "3341491 new file 117\n",
      "3359427 new file 118\n",
      "3377333 new file 119\n",
      "3406632 new file 120\n",
      "3413817 new file 121\n",
      "3502617 new file 122\n",
      "3520516 new file 123\n",
      "3582515 new file 124\n",
      "3600367 new file 125\n",
      "3629666 new file 126\n",
      "3647544 new file 127\n",
      "3665414 new file 128\n",
      "3727413 new file 129\n",
      "3745330 new file 130\n",
      "3752515 new file 131\n",
      "3779514 new file 132\n",
      "3786707 new file 133\n",
      "3861106 new file 134\n",
      "3888105 new file 135\n",
      "3917404 new file 136\n",
      "3944403 new file 137\n",
      "3971402 new file 138\n",
      "4000701 new file 139\n",
      "4018575 new file 140\n",
      "4036453 new file 141\n",
      "4063452 new file 142\n",
      "4092751 new file 143\n",
      "4096201 new file 144\n",
      "4103335 new file 145\n",
      "4132634 new file 146\n",
      "4161933 new file 147\n",
      "4191232 new file 148\n",
      "4218231 new file 149\n",
      "4307031 new file 150\n",
      "4334030 new file 151\n",
      "4363329 new file 152\n",
      "4420328 new file 153\n",
      "4438214 new file 154\n",
      "4445403 new file 155\n",
      "4474702 new file 156\n",
      "4481882 new file 157\n",
      "4499698 new file 158\n",
      "4517615 new file 159\n",
      "4546914 new file 160\n",
      "4576213 new file 161\n",
      "4594106 new file 162\n",
      "4612042 new file 163\n",
      "4619228 new file 164\n",
      "4646227 new file 165\n",
      "4673226 new file 166\n",
      "4702525 new file 167\n",
      "4731824 new file 168\n",
      "4738881 new file 169\n",
      "4746051 new file 170\n",
      "4775350 new file 171\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 27>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     45\u001b[0m         \u001b[38;5;28mprint\u001b[39m(i, ifile, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError predict\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 46\u001b[0m \u001b[43mq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m>\u001b[39m delay\u001b[38;5;241m+\u001b[39mwindow_size:\n\u001b[0;32m     48\u001b[0m     xd, yd \u001b[38;5;241m=\u001b[39m q\u001b[38;5;241m.\u001b[39mget()\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\3W\\lib\\queue.py:150\u001b[0m, in \u001b[0;36mQueue.put\u001b[1;34m(self, item, block, timeout)\u001b[0m\n\u001b[0;32m    148\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m Full\n\u001b[0;32m    149\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_full\u001b[38;5;241m.\u001b[39mwait(remaining)\n\u001b[1;32m--> 150\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_put\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munfinished_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_empty\u001b[38;5;241m.\u001b[39mnotify()\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\3W\\lib\\queue.py:214\u001b[0m, in \u001b[0;36mQueue._put\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_put\u001b[39m(\u001b[38;5;28mself\u001b[39m, item):\n\u001b[1;32m--> 214\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqueue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import queue\n",
    "q = queue.Queue()\n",
    "\n",
    "delay = 3600\n",
    "window_size = 900\n",
    "\n",
    "rmean = utils.Rolling(stats.Mean(), window_size=window_size)\n",
    "rSEM = utils.Rolling(stats.SEM(ddof=1), window_size=window_size)\n",
    "rMax = stats.RollingMax(window_size=window_size)\n",
    "rMin = stats.RollingMin(window_size=window_size)\n",
    "model = compose.TransformerUnion()\n",
    "for f in flist:\n",
    "    model += fx.Agg(on=f, by = None, how=rmean)\n",
    "    model += fx.Agg(on=f, by = None, how=rSEM)\n",
    "    model += fx.Agg(on=f, by = None, how=rMax)\n",
    "    model += fx.Agg(on=f, by = None, how=rMin)\n",
    "\n",
    "arfc = ensemble.AdaptiveRandomForestClassifier(seed=200560, leaf_prediction=\"nba\")\n",
    "report = metrics.ClassificationReport()\n",
    "\n",
    "gen = CustomGen(train_df, flist, 'class', scaleb=True, out_time=False, ifileb=True)\n",
    "\n",
    "lastfile = 0\n",
    "ys_real = []\n",
    "ys_pred = []\n",
    "j = 0\n",
    "for i, (ifile, x, y) in enumerate(gen.iter(max_n=None)):\n",
    "    if ifile != lastfile:\n",
    "        model = model.clone()\n",
    "        lastfile = ifile\n",
    "        j = 0\n",
    "        print(i, 'new file', ifile)\n",
    "    xt = model.transform_one(x)\n",
    "    if j >= window_size:\n",
    "        if i > delay+window_size+1:\n",
    "            try:\n",
    "                y_pred = arfc.predict_one(xt)\n",
    "                if y_pred is not None:\n",
    "                    ys_pred.append(y_pred)\n",
    "                    ys_real.append(y)\n",
    "                    report = report.update(y, y_pred)\n",
    "                else:\n",
    "                    print('Predicts None', i, j)\n",
    "            except:\n",
    "                print(i, ifile, 'Error predict')\n",
    "        q.put((xt, y))\n",
    "        if i > delay+window_size:\n",
    "            xd, yd = q.get()\n",
    "            try:\n",
    "                arfc.learn_one(xd, yd)\n",
    "            except:\n",
    "                print(i, ifile, 'Error learn')\n",
    "    j += 1\n",
    "print(report)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26999 new file 1\n",
      "56298 new file 2\n",
      "83297 new file 3\n",
      "112596 new file 4\n",
      "141895 new file 5\n",
      "149063 new file 6\n",
      "156197 new file 7\n",
      "185496 new file 8\n",
      "203444 new file 9\n",
      "210635 new file 10\n",
      "           Precision   Recall    F1       Support  \n",
      "                                                   \n",
      "       0       0.00%     0.00%    0.00%     24837  \n",
      "       4       0.00%     0.00%    0.00%     18793  \n",
      "       5      40.19%   100.00%   57.34%     96496  \n",
      "       6       0.00%     0.00%    0.00%     35998  \n",
      "     101       0.00%     0.00%    0.00%     32477  \n",
      "     105       0.00%     0.00%    0.00%       171  \n",
      "     106       0.00%     0.00%    0.00%       144  \n",
      "                                                   \n",
      "   Macro       5.74%    14.29%    8.19%            \n",
      "   Micro      40.19%    40.19%   40.19%            \n",
      "Weighted      16.15%    40.19%   23.04%            \n",
      "\n",
      "                  40.19% accuracy                  \n"
     ]
    }
   ],
   "source": [
    "gen_test = CustomGen(test_df, flist, 'class', scaleb=True, out_time=False, ifileb=True)\n",
    "report = metrics.ClassificationReport()\n",
    "\n",
    "lastfile = 0\n",
    "ys_real = []\n",
    "ys_pred = []\n",
    "j = 0\n",
    "for i, (ifile, x, y) in enumerate(gen_test.iter(max_n=250000)):\n",
    "    if ifile != lastfile:\n",
    "        model = model.clone()\n",
    "        lastfile = ifile\n",
    "        j = 0\n",
    "        print(i, 'new file', ifile)\n",
    "    xt = model.transform_one(x)\n",
    "    if j >= window_size:\n",
    "        try:\n",
    "            y_pred = arfc.predict_one(xt)\n",
    "            if y_pred is not None:\n",
    "                ys_pred.append(y_pred)\n",
    "                ys_real.append(y)\n",
    "                report = report.update(y, y_pred)\n",
    "            else:\n",
    "                print('Predicts None', i, j)\n",
    "        except:\n",
    "            print(i, ifile, 'Error predict')\n",
    "    j += 1\n",
    "print(report)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5]), array([240101], dtype=int64))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(ys_pred, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.clone()\n",
    "evaluate.progressive_val_score(\n",
    "    model = model,\n",
    "    dataset = stream.iter_pandas(df_clean[flist], df_clean['class']),\n",
    "    metric = metrics.Accuracy(),\n",
    "    delay = 0, \n",
    "    print_every = 900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drift test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary function to plot the data\n",
    "def plot_data(stream, sts, warnings=None, drifts=None):\n",
    "    fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, figsize=(12, 6), sharex=True)\n",
    "    ax1.grid; ax2.grid\n",
    "    ax1.set_ylabel('Stream'); ax2.set_ylabel('Stat')\n",
    "    fig.suptitle('Drift test')\n",
    "    ax1.plot(stream, label='Stream')\n",
    "    ax2.plot(sts, label='stats')\n",
    "    if drifts is not None:\n",
    "        for drift_detected in drifts:\n",
    "            ax2.axvline(stream.index[drift_detected], color='red', linewidth=0.5)\n",
    "    if warnings is not None:\n",
    "        for warning_detected in warnings:\n",
    "            ax2.axvline(stream.index[warning_detected], color='green', linewidth=0.25)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tk.load_instance(real_instances[real_instances.label==3].iloc[0])\n",
    "df_clean = df[flist+['class']].dropna()\n",
    "\n",
    "#sem = stats.RollingSEM(ddof=1, window_size=30)\n",
    "sem = stats.SEM()\n",
    "\n",
    "f = 'P-TPT'\n",
    "#drift_detector = drift.ADWIN(delta=0.002)\n",
    "drift_detector = drift.DDM(min_num_instances=600)\n",
    "warnings = []\n",
    "drifts = []\n",
    "sems = []\n",
    "\n",
    "for i, val in enumerate(df_clean[f]):\n",
    "    sems.append(sem.update(val).get())\n",
    "    in_drift, in_warning = drift_detector.update(sems[-1])   # Data is processed one sample at a time\n",
    "    if in_warning:\n",
    "        # The drift detector indicates after each sample if there is a drift in the data\n",
    "        #print(f'Change detected at index {i}')\n",
    "        warnings.append(i)\n",
    "#        drift_detector.reset()   # As a best practice, we reset the detector\n",
    "    if in_drift:\n",
    "        # The drift detector indicates after each sample if there is a drift in the data\n",
    "        print(f'Change detected at index {i}, {x}')\n",
    "        drifts.append(i)\n",
    "#        drift_detector.reset()   # As a best practice, we reset the detector\n",
    "\n",
    "plot_data(df_clean[f], pd.Series(sems, index=df_clean.index), warnings=warnings, drifts=drifts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomaly detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tk.load_instance(real_instances[real_instances.label==2].iloc[0])\n",
    "df_clean = df[flist+['class']].dropna()\n",
    "\n",
    "f = 'T-TPT'\n",
    "\n",
    "detector = anomaly.GaussianScorer(window_size=None, grace_period=300)\n",
    "\n",
    "anomalies = []\n",
    "\n",
    "for i, val in enumerate(df_clean[f]):\n",
    "    anomalies.append(detector.score_one(None, val))\n",
    "    detector = detector.learn_one(None, val)\n",
    "anomalies = pd.Series(anomalies, index=df_clean.index)\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(nrows=3, ncols=1, figsize=(12, 6), sharex=True)\n",
    "ax1.grid\n",
    "ax2.grid\n",
    "ax3.grid\n",
    "ax1.plot(df_clean[f], label='Stream', color='blue')\n",
    "ax2.plot(anomalies, label='Anomalies prob', color='red')\n",
    "ax2.axhline(0.95, color='green')\n",
    "ax3.plot(df_clean['class'], label='class', color='black')\n",
    "\n",
    "plt.tight_layout\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3W",
   "language": "python",
   "name": "3w"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Sumário",
   "title_sidebar": "Sumário",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
